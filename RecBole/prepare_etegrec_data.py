import json
import pandas as pd
import os
from collections import defaultdict
from tqdm import tqdm
import numpy as np

def load_recbole_interactions(inter_file):
    """
    åŠ è½½ RecBole çš„ .inter æ–‡ä»¶
    """
    print(f"ğŸ“– æ­£åœ¨è¯»å– RecBole äº¤äº’æ–‡ä»¶: {inter_file}")
    
    data = []
    with open(inter_file, 'r', encoding='utf-8') as f:
        # è·³è¿‡è¡¨å¤´
        header = f.readline().strip().split('\t')
        print(f"   è¡¨å¤´: {header}")
        
        # è¯»å–æ•°æ®
        for line in f:
            parts = line.strip().split('\t')
            if len(parts) >= 3:
                data.append({
                    'user_id': parts[0],
                    'item_id': parts[1],
                    'rating': float(parts[2]) if len(parts) > 2 else 1.0,
                    'timestamp': float(parts[3]) if len(parts) > 3 else 0.0
                })
    
    df = pd.DataFrame(data)
    print(f"âœ… è¯»å–äº† {len(df)} æ¡äº¤äº’")
    return df

def split_sequences_by_user(df, max_seq_length=50):
    """
    æŒ‰ç”¨æˆ·åˆ’åˆ†æ•°æ®ï¼Œä½¿ç”¨ leave-one-out ç­–ç•¥
    ğŸ”§ é™åˆ¶åºåˆ—æœ€å¤§é•¿åº¦ï¼ˆä¸ä½œè€…ä¸€è‡´ï¼‰
    
    Args:
        df: äº¤äº’æ•°æ®
        max_seq_length: æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤50ï¼‰
    """
    print(f"\nğŸ”ª æ­£åœ¨åˆ’åˆ†æ•°æ®é›†...")
    print(f"   ç­–ç•¥: Leave-one-out")
    print(f"   æœ€å¤§åºåˆ—é•¿åº¦: {max_seq_length}")
    
    # æŒ‰ç”¨æˆ·å’Œæ—¶é—´æ’åº
    df = df.sort_values(['user_id', 'timestamp']).reset_index(drop=True)
    
    train_sequences = []
    valid_sequences = []
    test_sequences = []
    
    # æŒ‰ç”¨æˆ·åˆ†ç»„
    user_groups = df.groupby('user_id')
    print(f"   ç”¨æˆ·æ•°: {len(user_groups)}")
    
    stats = {
        'total_users': 0,
        'train_users': 0,
        'valid_users': 0,
        'test_users': 0,
        'skipped_users': 0,
        'truncated_sequences': 0
    }
    
    for user_id, group in tqdm(user_groups, desc="å¤„ç†ç”¨æˆ·"):
        stats['total_users'] += 1
        interactions = group['item_id'].tolist()
        n = len(interactions)
        
        if n < 3:
            stats['skipped_users'] += 1
            continue
        
        # ============ è®­ç»ƒé›†ï¼šå¢é‡åºåˆ— ============
        for i in range(1, n - 2):
            # ğŸ”§ é™åˆ¶å†å²é•¿åº¦
            history = interactions[:i]
            if len(history) > max_seq_length:
                history = history[-max_seq_length:]
                stats['truncated_sequences'] += 1
            
            train_sequences.append({
                'user_id': user_id,
                'inter_history': history,
                'target_id': interactions[i]
            })
        
        if n > 3:
            stats['train_users'] += 1
        
        # ============ éªŒè¯é›† ============
        valid_history = interactions[:-2]
        if len(valid_history) > max_seq_length:
            valid_history = valid_history[-max_seq_length:]
            stats['truncated_sequences'] += 1
        
        valid_sequences.append({
            'user_id': user_id,
            'inter_history': valid_history,
            'target_id': interactions[-2]
        })
        stats['valid_users'] += 1
        
        # ============ æµ‹è¯•é›† ============
        test_history = interactions[:-1]
        if len(test_history) > max_seq_length:
            test_history = test_history[-max_seq_length:]
            stats['truncated_sequences'] += 1
        
        test_sequences.append({
            'user_id': user_id,
            'inter_history': test_history,
            'target_id': interactions[-1]
        })
        stats['test_users'] += 1
    
    print(f"\nâœ… æ•°æ®åˆ’åˆ†å®Œæˆ:")
    print(f"   æ€»ç”¨æˆ·æ•°: {stats['total_users']:,}")
    print(f"   è®­ç»ƒé›†åºåˆ—: {len(train_sequences):,} (æ¥è‡ª {stats['train_users']:,} ä¸ªç”¨æˆ·)")
    print(f"   éªŒè¯é›†åºåˆ—: {len(valid_sequences):,} (æ¥è‡ª {stats['valid_users']:,} ä¸ªç”¨æˆ·)")
    print(f"   æµ‹è¯•é›†åºåˆ—: {len(test_sequences):,} (æ¥è‡ª {stats['test_users']:,} ä¸ªç”¨æˆ·)")
    print(f"   è·³è¿‡ç”¨æˆ·: {stats['skipped_users']:,} (äº¤äº’å°‘äº3æ¬¡)")
    print(f"   æˆªæ–­åºåˆ—: {stats['truncated_sequences']:,} (è¶…è¿‡ {max_seq_length} é•¿åº¦)")
    
    return train_sequences, valid_sequences, test_sequences

def save_jsonl(data, output_file):
    """
    ä¿å­˜ä¸º JSONL æ ¼å¼
    """
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°: {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in data:
            json_obj = {
                'user_id': item['user_id'],
                'target_id': item['target_id'],
                'inter_history': item['inter_history']
            }
            f.write(json.dumps(json_obj, ensure_ascii=False) + '\n')
    
    print(f"âœ… å·²ä¿å­˜ {len(data)} æ¡è®°å½•")

def verify_data(train_seqs, valid_seqs, test_seqs, max_seq_length):
    """
    éªŒè¯æ•°æ®è´¨é‡
    """
    print(f"\n{'='*70}")
    print(f"ğŸ” æ•°æ®è´¨é‡éªŒè¯")
    print(f"{'='*70}")
    
    all_seqs = train_seqs + valid_seqs + test_seqs
    
    # æ£€æŸ¥1: å†å²é•¿åº¦
    hist_lens = [len(seq['inter_history']) for seq in all_seqs]
    max_len = max(hist_lens)
    
    print(f"\nâœ… å†å²é•¿åº¦æ£€æŸ¥:")
    print(f"   æœ€å¤§é•¿åº¦: {max_len}")
    print(f"   é™åˆ¶é•¿åº¦: {max_seq_length}")
    if max_len <= max_seq_length:
        print(f"   âœ… æ‰€æœ‰åºåˆ—é•¿åº¦éƒ½åœ¨é™åˆ¶èŒƒå›´å†…")
    else:
        print(f"   âŒ å‘ç°è¶…é•¿åºåˆ—ï¼")
    
    # æ£€æŸ¥2: ç©ºå†å²
    empty_count = sum(1 for seq in all_seqs if len(seq['inter_history']) == 0)
    print(f"\nâœ… ç©ºå†å²æ£€æŸ¥:")
    print(f"   ç©ºå†å²åºåˆ—æ•°: {empty_count}")
    if empty_count == 0:
        print(f"   âœ… æ²¡æœ‰ç©ºå†å²åºåˆ—")
    else:
        print(f"   âŒ å‘ç° {empty_count} ä¸ªç©ºå†å²åºåˆ—")
    
    # æ£€æŸ¥3: ç»Ÿè®¡åˆ†å¸ƒ
    print(f"\nâœ… ç»Ÿè®¡åˆ†å¸ƒ:")
    for name, seqs in [('è®­ç»ƒé›†', train_seqs), ('éªŒè¯é›†', valid_seqs), ('æµ‹è¯•é›†', test_seqs)]:
        lens = [len(s['inter_history']) for s in seqs]
        print(f"   {name}:")
        print(f"      å¹³å‡é•¿åº¦: {np.mean(lens):.2f}")
        print(f"      ä¸­ä½æ•°: {np.median(lens):.2f}")
        print(f"      æœ€å¤§é•¿åº¦: {np.max(lens)}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 70)
    print("ğŸµ ETEGRec æ•°æ®å‡†å¤‡å·¥å…· - Musical Instruments 2023 (ä¼˜åŒ–ç‰ˆ)")
    print("=" * 70)
    print(f"å½“å‰æ—¶é—´: 2025-11-14 09:12:40 UTC")
    print(f"ç”¨æˆ·: YYYYXL1004")
    print("=" * 70)
    
    # ============ é…ç½® ============
    BASE_DIR = './dataset/Instruments2023'
    INTER_FILE = os.path.join(BASE_DIR, 'Instruments2023.inter')
    MAP_FILE = os.path.join(BASE_DIR, 'Instruments2023.emb_map.json')
    OUTPUT_DIR = BASE_DIR
    DATASET_NAME = 'Instruments2023'
    
    # ğŸ”§ å…³é”®å‚æ•°ï¼ˆä¸ä½œè€…å¯¹é½ï¼‰
    MAX_SEQ_LENGTH = 50  # é™åˆ¶åºåˆ—æœ€å¤§é•¿åº¦ä¸º50
    
    print(f"\nâš™ï¸  é…ç½®å‚æ•°:")
    print(f"   æœ€å¤§åºåˆ—é•¿åº¦: {MAX_SEQ_LENGTH} (ä¸ä½œè€…ä¸€è‡´)")
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(INTER_FILE):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°äº¤äº’æ–‡ä»¶ {INTER_FILE}")
        return
    
    if not os.path.exists(MAP_FILE):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æ˜ å°„æ–‡ä»¶ {MAP_FILE}")
        print(f"   è¯·å…ˆè¿è¡Œ train_sasrec_instruments.py ç”Ÿæˆæ˜ å°„æ–‡ä»¶")
        return
    
    # ============ æ­¥éª¤ 1: åŠ è½½æ•°æ® ============
    df = load_recbole_interactions(INTER_FILE)
    
    # æ£€æŸ¥æ˜ å°„
    print(f"\nğŸ“– æ­£åœ¨è¯»å– item2id æ˜ å°„: {MAP_FILE}")
    with open(MAP_FILE, 'r', encoding='utf-8') as f:
        item2id = json.load(f)
    print(f"âœ… æ˜ å°„æ¡ç›®æ•°: {len(item2id)}")
    if '[PAD]' in item2id:
        print(f"   åŒ…å« [PAD] token: âœ…")
    else:
        print(f"   âš ï¸  è­¦å‘Š: æ˜ å°„ä¸åŒ…å« [PAD] token")
    
    # ============ æ­¥éª¤ 2: åˆ’åˆ†æ•°æ®é›† ============
    train_sequences, valid_sequences, test_sequences = split_sequences_by_user(
        df, 
        max_seq_length=MAX_SEQ_LENGTH
    )
    
    # ============ æ­¥éª¤ 3: éªŒè¯æ•°æ® ============
    verify_data(train_sequences, valid_sequences, test_sequences, MAX_SEQ_LENGTH)
    
    # ============ æ­¥éª¤ 4: ä¿å­˜æ–‡ä»¶ ============
    print(f"\n{'='*70}")
    print(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶...")
    print(f"{'='*70}")
    
    train_file = os.path.join(OUTPUT_DIR, f'{DATASET_NAME}.train.jsonl')
    valid_file = os.path.join(OUTPUT_DIR, f'{DATASET_NAME}.valid.jsonl')
    test_file = os.path.join(OUTPUT_DIR, f'{DATASET_NAME}.test.jsonl')
    
    save_jsonl(train_sequences, train_file)
    save_jsonl(valid_sequences, valid_file)
    save_jsonl(test_sequences, test_file)
    
    # ============ æ­¥éª¤ 5: æ˜¾ç¤ºæ ·ä¾‹ ============
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ•°æ®æ ·ä¾‹")
    print(f"{'='*70}")
    
    print(f"\nè®­ç»ƒé›†å‰3æ¡:")
    for i, seq in enumerate(train_sequences[:3], 1):
        hist_str = str(seq['inter_history'][:3])
        if len(seq['inter_history']) > 3:
            hist_str = hist_str[:-1] + ', ...]'
        print(f"   {i}. user={seq['user_id'][:20]}..., target={seq['target_id']}, history_len={len(seq['inter_history'])}, history={hist_str}")
    
    print(f"\néªŒè¯é›†å‰3æ¡:")
    for i, seq in enumerate(valid_sequences[:3], 1):
        hist_str = str(seq['inter_history'][:3])
        if len(seq['inter_history']) > 3:
            hist_str = hist_str[:-1] + ', ...]'
        print(f"   {i}. user={seq['user_id'][:20]}..., target={seq['target_id']}, history_len={len(seq['inter_history'])}, history={hist_str}")
    
    # ============ æ€»ç»“ ============
    print(f"\n{'='*70}")
    print(f"ğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆ!")
    print(f"{'='*70}")
    
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. {train_file}")
    print(f"      - åºåˆ—æ•°: {len(train_sequences):,}")
    print(f"   2. {valid_file}")
    print(f"      - åºåˆ—æ•°: {len(valid_sequences):,}")
    print(f"   3. {test_file}")
    print(f"      - åºåˆ—æ•°: {len(test_sequences):,}")
    
    print(f"\nğŸ“ å·²æœ‰çš„æ–‡ä»¶:")
    print(f"   4. {MAP_FILE}")
    print(f"   5. {os.path.join(OUTPUT_DIR, f'{DATASET_NAME}_emb_256.npy')}")
    
    print(f"\nâœ¨ ä¸ä½œè€…æ•°æ®é›†å¯¹é½:")
    print(f"   âœ… æœ€å¤§åºåˆ—é•¿åº¦é™åˆ¶ä¸º {MAX_SEQ_LENGTH}")
    print(f"   âœ… æ•°æ®æ ¼å¼: {{user_id, target_id, inter_history}}")
    print(f"   âœ… æ˜ å°„åŒ…å« [PAD] token")
    
    print(f"\nâœ¨ ä¸‹ä¸€æ­¥: è®­ç»ƒ ETEGRec!")
    print(f"   1. åˆ›å»ºé…ç½®æ–‡ä»¶ config/instruments.yaml")
    print(f"   2. ä¿®æ”¹ run.sh ä¸­çš„ DATASET=Instruments2023")
    print(f"   3. è¿è¡Œ: bash run.sh")
    
    print(f"\n{'='*70}")

if __name__ == '__main__':
    main()