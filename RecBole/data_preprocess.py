import json
import pandas as pd
import os
from collections import defaultdict
from datetime import datetime

def load_reviews(review_file):
    """
    åŠ è½½ Musical_Instruments.jsonl (ç”¨æˆ·è¯„è®ºæ•°æ®)
    
    å…¸å‹å­—æ®µï¼š
    - rating: è¯„åˆ†
    - title: è¯„è®ºæ ‡é¢˜
    - text: è¯„è®ºæ–‡æœ¬
    - asin: å•†å“ID
    - parent_asin: çˆ¶å•†å“ID
    - user_id: ç”¨æˆ·ID
    - timestamp: æ—¶é—´æˆ³(æ¯«ç§’)
    - verified_purchase: æ˜¯å¦éªŒè¯è´­ä¹°
    - helpful_vote: æœ‰ç”¨æŠ•ç¥¨æ•°
    """
    print("ğŸ“– æ­£åœ¨è¯»å–è¯„è®ºæ•°æ®...")
    reviews = []
    
    with open(review_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                review = json.loads(line.strip())
                reviews.append(review)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œè§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… è¯»å–äº† {len(reviews)} æ¡è¯„è®º")
    return reviews

def load_metadata(meta_file):
    """
    åŠ è½½ meta_Musical_Instruments.jsonl (å•†å“å…ƒæ•°æ®)
    
    å…¸å‹å­—æ®µï¼š
    - main_category: ä¸»ç±»åˆ«
    - title: å•†å“æ ‡é¢˜
    - average_rating: å¹³å‡è¯„åˆ†
    - rating_number: è¯„åˆ†æ•°é‡
    - features: ç‰¹å¾åˆ—è¡¨
    - description: æè¿°
    - price: ä»·æ ¼
    - images: å›¾ç‰‡åˆ—è¡¨
    - videos: è§†é¢‘åˆ—è¡¨
    - store: åº—é“º
    - categories: ç±»åˆ«åˆ—è¡¨
    - details: è¯¦ç»†ä¿¡æ¯
    - parent_asin: çˆ¶å•†å“ID
    - bought_together: ä¸€èµ·è´­ä¹°çš„å•†å“
    """
    print("ğŸ“– æ­£åœ¨è¯»å–å•†å“å…ƒæ•°æ®...")
    metadata = {}
    
    with open(meta_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                item = json.loads(line.strip())
                # ä½¿ç”¨ parent_asin ä½œä¸ºä¸»é”®
                asin = item.get('parent_asin') or item.get('asin')
                if asin:
                    metadata[asin] = item
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œè§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… è¯»å–äº† {len(metadata)} ä¸ªå•†å“çš„å…ƒæ•°æ®")
    return metadata

def preprocess_reviews(reviews, min_user_interactions=5, min_item_interactions=5):
    """
    é¢„å¤„ç†è¯„è®ºæ•°æ®
    """
    print("\nğŸ”§ å¼€å§‹é¢„å¤„ç†è¯„è®ºæ•°æ®...")
    
    # è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(reviews)
    
    print(f"åŸå§‹æ•°æ®: {len(df)} æ¡äº¤äº’")
    print(f"å”¯ä¸€ç”¨æˆ·æ•°: {df['user_id'].nunique()}")
    print(f"å”¯ä¸€å•†å“æ•°: {df['parent_asin'].nunique()}")
    
    # 1. ä½¿ç”¨ parent_asin ä½œä¸º item_id
    df['item_id'] = df['parent_asin']
    
    # 2. å¤„ç†æ—¶é—´æˆ³ (æ¯«ç§’ -> ç§’)
    if 'timestamp' in df.columns:
        df['timestamp'] = df['timestamp'] / 1000  # è½¬æ¢ä¸ºç§’
    else:
        # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼ŒæŒ‰é¡ºåºç”Ÿæˆ
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ° timestamp å­—æ®µï¼Œå°†æŒ‰é¡ºåºç”Ÿæˆ")
        df['timestamp'] = range(len(df))
    
    # 3. è¿‡æ»¤ç¼ºå¤±å€¼
    df = df.dropna(subset=['user_id', 'item_id', 'timestamp'])
    print(f"å»é™¤ç¼ºå¤±å€¼å: {len(df)} æ¡äº¤äº’")
    
    # 4. è¿‡æ»¤ä½é¢‘ç”¨æˆ·
    user_counts = df['user_id'].value_counts()
    valid_users = user_counts[user_counts >= min_user_interactions].index
    df = df[df['user_id'].isin(valid_users)]
    print(f"è¿‡æ»¤ä½é¢‘ç”¨æˆ·å (>={min_user_interactions}æ¬¡): {len(df)} æ¡äº¤äº’, {df['user_id'].nunique()} ä¸ªç”¨æˆ·")
    
    # 5. è¿‡æ»¤ä½é¢‘ç‰©å“
    item_counts = df['item_id'].value_counts()
    valid_items = item_counts[item_counts >= min_item_interactions].index
    df = df[df['item_id'].isin(valid_items)]
    print(f"è¿‡æ»¤ä½é¢‘ç‰©å“å (>={min_item_interactions}æ¬¡): {len(df)} æ¡äº¤äº’, {df['item_id'].nunique()} ä¸ªç‰©å“")
    
    # 6. æŒ‰ç”¨æˆ·å’Œæ—¶é—´æ’åº
    df = df.sort_values(['user_id', 'timestamp'])
    
    # 7. é‡ç½®ç´¢å¼•
    df = df.reset_index(drop=True)
    
    print(f"\nâœ… é¢„å¤„ç†å®Œæˆï¼")
    print(f"   æœ€ç»ˆç”¨æˆ·æ•°: {df['user_id'].nunique()}")
    print(f"   æœ€ç»ˆç‰©å“æ•°: {df['item_id'].nunique()}")
    print(f"   æœ€ç»ˆäº¤äº’æ•°: {len(df)}")
    print(f"   ç¨€ç–åº¦: {1 - len(df) / (df['user_id'].nunique() * df['item_id'].nunique()):.4%}")
    
    return df

def save_recbole_format(df, output_dir, dataset_name='Instruments2023'):
    """
    ä¿å­˜ä¸º RecBole æ ¼å¼
    """
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ä¸º RecBole æ ¼å¼...")
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ä¿å­˜ .inter æ–‡ä»¶
    inter_file = os.path.join(output_dir, f'{dataset_name}.inter')
    
    with open(inter_file, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´ (æŒ‡å®šå­—æ®µç±»å‹)
        f.write('user_id:token\titem_id:token\trating:float\ttimestamp:float\n')
        
        # å†™å…¥æ•°æ®
        for _, row in df.iterrows():
            user_id = str(row['user_id'])
            item_id = str(row['item_id'])
            rating = row.get('rating', 5.0)
            timestamp = row['timestamp']
            f.write(f"{user_id}\t{item_id}\t{rating}\t{timestamp}\n")
    
    print(f"âœ… å·²ä¿å­˜äº¤äº’æ–‡ä»¶: {inter_file}")
    
    # 2. åˆ›å»º item2id æ˜ å°„ (ç”¨äºåç»­ç”Ÿæˆ .emb_map.json)
    unique_items = sorted(df['item_id'].unique())
    item2id = {item: idx + 1 for idx, item in enumerate(unique_items)}  # ä»1å¼€å§‹ï¼Œ0ç•™ç»™padding
    
    map_file = os.path.join(output_dir, 'item2id_raw.json')
    with open(map_file, 'w', encoding='utf-8') as f:
        json.dump(item2id, f, indent=2)
    print(f"âœ… å·²ä¿å­˜ç‰©å“æ˜ å°„: {map_file}")
    
    # 3. ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'dataset_name': dataset_name,
        'num_users': int(df['user_id'].nunique()),
        'num_items': int(df['item_id'].nunique()),
        'num_interactions': int(len(df)),
        'sparsity': float(1 - len(df) / (df['user_id'].nunique() * df['item_id'].nunique())),
        'avg_interactions_per_user': float(len(df) / df['user_id'].nunique()),
        'avg_interactions_per_item': float(len(df) / df['item_id'].nunique()),
        'timestamp_range': {
            'min': float(df['timestamp'].min()),
            'max': float(df['timestamp'].max()),
        }
    }
    
    stats_file = os.path.join(output_dir, 'dataset_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2)
    print(f"âœ… å·²ä¿å­˜ç»Ÿè®¡ä¿¡æ¯: {stats_file}")
    
    return item2id

def save_item_metadata(metadata, valid_items, output_dir, dataset_name='Instruments2023'):
    """
    ä¿å­˜ç‰©å“å…ƒæ•°æ® (å¯é€‰ï¼ŒRecBole å¯ä»¥ä½¿ç”¨)
    """
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç‰©å“å…ƒæ•°æ®...")
    
    item_file = os.path.join(output_dir, f'{dataset_name}.item')
    
    with open(item_file, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´
        f.write('item_id:token\ttitle:token_seq\taverage_rating:float\trating_number:float\tprice:float\n')
        
        # å†™å…¥æ•°æ®
        for item_id in valid_items:
            if item_id in metadata:
                item = metadata[item_id]
                title = str(item.get('title', '')).replace('\t', ' ').replace('\n', ' ')
                avg_rating = item.get('average_rating', 0.0)
                rating_num = item.get('rating_number', 0)
                price = item.get('price', 0.0)
                
                # å¤„ç†ä»·æ ¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰
                if isinstance(price, str):
                    try:
                        price = float(price.replace('$', '').replace(',', ''))
                    except:
                        price = 0.0
                
                f.write(f"{item_id}\t{title}\t{avg_rating}\t{rating_num}\t{price}\n")
    
    print(f"âœ… å·²ä¿å­˜ç‰©å“å…ƒæ•°æ®: {item_file}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 60)
    print("ğŸµ Amazon 2023 Musical Instruments æ•°æ®é›†è½¬æ¢å·¥å…·")
    print("=" * 60)
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ç”¨æˆ·: YYYYXL1004")
    print("=" * 60)
    
    # é…ç½®
    BASE_DIR = './dataset/Instruments2023'
    REVIEW_FILE = os.path.join(BASE_DIR, 'Musical_Instruments.jsonl')
    META_FILE = os.path.join(BASE_DIR, 'meta_Musical_Instruments.jsonl')
    OUTPUT_DIR = BASE_DIR
    DATASET_NAME = 'Instruments2023'
    
    # é¢„å¤„ç†å‚æ•°
    MIN_USER_INTERACTIONS = 5  # ç”¨æˆ·æœ€å°‘äº¤äº’æ¬¡æ•°
    MIN_ITEM_INTERACTIONS = 5  # ç‰©å“æœ€å°‘äº¤äº’æ¬¡æ•°
    
    print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶:")
    print(f"   è¯„è®ºæ•°æ®: {REVIEW_FILE}")
    print(f"   å…ƒæ•°æ®: {META_FILE}")
    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"\nâš™ï¸  è¿‡æ»¤å‚æ•°:")
    print(f"   æœ€å°‘ç”¨æˆ·äº¤äº’: {MIN_USER_INTERACTIONS}")
    print(f"   æœ€å°‘ç‰©å“äº¤äº’: {MIN_ITEM_INTERACTIONS}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(REVIEW_FILE):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°è¯„è®ºæ–‡ä»¶ {REVIEW_FILE}")
        return
    if not os.path.exists(META_FILE):
        print(f"\nâš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°å…ƒæ•°æ®æ–‡ä»¶ {META_FILE}ï¼Œå°†è·³è¿‡å…ƒæ•°æ®å¤„ç†")
        metadata = {}
    else:
        metadata = load_metadata(META_FILE)
    
    # æ­¥éª¤ 1: åŠ è½½è¯„è®ºæ•°æ®
    reviews = load_reviews(REVIEW_FILE)
    
    # æ­¥éª¤ 2: é¢„å¤„ç†
    df = preprocess_reviews(reviews, MIN_USER_INTERACTIONS, MIN_ITEM_INTERACTIONS)
    
    # æ­¥éª¤ 3: ä¿å­˜ RecBole æ ¼å¼
    item2id = save_recbole_format(df, OUTPUT_DIR, DATASET_NAME)
    
    # æ­¥éª¤ 4: ä¿å­˜ç‰©å“å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    if metadata:
        valid_items = df['item_id'].unique()
        save_item_metadata(metadata, valid_items, OUTPUT_DIR, DATASET_NAME)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®è½¬æ¢å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. {OUTPUT_DIR}/{DATASET_NAME}.inter          - RecBole äº¤äº’æ–‡ä»¶ âœ…")
    print(f"   2. {OUTPUT_DIR}/item2id_raw.json              - ç‰©å“IDæ˜ å°„")
    print(f"   3. {OUTPUT_DIR}/dataset_stats.json            - æ•°æ®é›†ç»Ÿè®¡")
    if metadata:
        print(f"   4. {OUTPUT_DIR}/{DATASET_NAME}.item          - ç‰©å“å…ƒæ•°æ® (å¯é€‰)")
    
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"   è¿è¡Œ: python train_sasrec_instruments.py")
    print("=" * 60)

if __name__ == '__main__':
    main()