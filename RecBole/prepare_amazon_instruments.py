import json
import pandas as pd
import os
from collections import defaultdict
from datetime import datetime
from tqdm import tqdm

def load_reviews(review_file):
    """
    åŠ è½½ Musical_Instruments.jsonl (ç”¨æˆ·è¯„è®ºæ•°æ®)
    """
    print("ğŸ“– æ­£åœ¨è¯»å–è¯„è®ºæ•°æ®...")
    reviews = []
    
    with open(review_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                review = json.loads(line.strip())
                reviews.append(review)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œè§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… è¯»å–äº† {len(reviews)} æ¡è¯„è®º")
    return reviews

def load_metadata(meta_file):
    """
    åŠ è½½ meta_Musical_Instruments.jsonl (å•†å“å…ƒæ•°æ®)
    """
    print("ğŸ“– æ­£åœ¨è¯»å–å•†å“å…ƒæ•°æ®...")
    metadata = {}
    
    with open(meta_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                item = json.loads(line.strip())
                # ä½¿ç”¨ parent_asin ä½œä¸ºä¸»é”®
                asin = item.get('parent_asin') or item.get('asin')
                if asin:
                    metadata[asin] = item
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œè§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… è¯»å–äº† {len(metadata)} ä¸ªå•†å“çš„å…ƒæ•°æ®")
    return metadata

def preprocess_reviews(reviews, min_user_interactions=5, min_item_interactions=5):
    """
    é¢„å¤„ç†è¯„è®ºæ•°æ® - ğŸ”§ ä½¿ç”¨è¿­ä»£è¿‡æ»¤ç¡®ä¿æ•°æ®è´¨é‡
    """
    print("\nğŸ”§ å¼€å§‹é¢„å¤„ç†è¯„è®ºæ•°æ®...")
    
    # è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(reviews)
    
    print(f"åŸå§‹æ•°æ®: {len(df)} æ¡äº¤äº’")
    print(f"å”¯ä¸€ç”¨æˆ·æ•°: {df['user_id'].nunique()}")
    print(f"å”¯ä¸€å•†å“æ•°: {df['parent_asin'].nunique()}")
    
    # 1. ä½¿ç”¨ parent_asin ä½œä¸º item_id
    df['item_id'] = df['parent_asin']
    
    # 2. å¤„ç†æ—¶é—´æˆ³ (æ¯«ç§’ -> ç§’)
    if 'timestamp' in df.columns:
        df['timestamp'] = df['timestamp'] / 1000  # è½¬æ¢ä¸ºç§’
    else:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ° timestamp å­—æ®µï¼Œå°†æŒ‰é¡ºåºç”Ÿæˆ")
        df['timestamp'] = range(len(df))
    
    # 3. è¿‡æ»¤ç¼ºå¤±å€¼
    df = df.dropna(subset=['user_id', 'item_id', 'timestamp'])
    print(f"å»é™¤ç¼ºå¤±å€¼å: {len(df)} æ¡äº¤äº’")
    
    # ğŸ”§ 4. è¿­ä»£è¿‡æ»¤ - ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
    print(f"\nğŸ”„ å¼€å§‹è¿­ä»£è¿‡æ»¤...")
    prev_len = -1
    iteration = 0
    
    while len(df) != prev_len:
        iteration += 1
        prev_len = len(df)
        
        # è¿‡æ»¤ä½é¢‘ç”¨æˆ·
        user_counts = df['user_id'].value_counts()
        valid_users = user_counts[user_counts >= min_user_interactions].index
        df = df[df['user_id'].isin(valid_users)]
        
        # è¿‡æ»¤ä½é¢‘ç‰©å“
        item_counts = df['item_id'].value_counts()
        valid_items = item_counts[item_counts >= min_item_interactions].index
        df = df[df['item_id'].isin(valid_items)]
        
        print(f"   è¿­ä»£ {iteration}: {len(df):,} æ¡äº¤äº’, {df['user_id'].nunique():,} ç”¨æˆ·, {df['item_id'].nunique():,} ç‰©å“")
    
    # 5. æŒ‰ç”¨æˆ·å’Œæ—¶é—´æ’åº
    df = df.sort_values(['user_id', 'timestamp'])
    
    # 6. é‡ç½®ç´¢å¼•
    df = df.reset_index(drop=True)
    
    print(f"\nâœ… é¢„å¤„ç†å®Œæˆï¼")
    print(f"   æœ€ç»ˆç”¨æˆ·æ•°: {df['user_id'].nunique():,}")
    print(f"   æœ€ç»ˆç‰©å“æ•°: {df['item_id'].nunique():,}")
    print(f"   æœ€ç»ˆäº¤äº’æ•°: {len(df):,}")
    print(f"   ç¨€ç–åº¦: {1 - len(df) / (df['user_id'].nunique() * df['item_id'].nunique()):.4%}")
    
    return df

def save_recbole_format(df, output_dir, dataset_name='Instruments2023'):
    """
    ä¿å­˜ä¸º RecBole æ ¼å¼
    """
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ä¸º RecBole æ ¼å¼...")
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ä¿å­˜ .inter æ–‡ä»¶
    inter_file = os.path.join(output_dir, f'{dataset_name}.inter')
    
    with open(inter_file, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´ (æŒ‡å®šå­—æ®µç±»å‹)
        f.write('user_id:token\titem_id:token\trating:float\ttimestamp:float\n')
        
        # å†™å…¥æ•°æ®
        for _, row in df.iterrows():
            user_id = str(row['user_id'])
            item_id = str(row['item_id'])
            rating = row.get('rating', 5.0)
            timestamp = row['timestamp']
            f.write(f"{user_id}\t{item_id}\t{rating}\t{timestamp}\n")
    
    print(f"âœ… å·²ä¿å­˜äº¤äº’æ–‡ä»¶: {inter_file}")
    
    # 2. ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'dataset_name': dataset_name,
        'num_users': int(df['user_id'].nunique()),
        'num_items': int(df['item_id'].nunique()),
        'num_interactions': int(len(df)),
        'sparsity': float(1 - len(df) / (df['user_id'].nunique() * df['item_id'].nunique())),
        'avg_interactions_per_user': float(len(df) / df['user_id'].nunique()),
        'avg_interactions_per_item': float(len(df) / df['item_id'].nunique()),
        'timestamp_range': {
            'min': float(df['timestamp'].min()),
            'max': float(df['timestamp'].max()),
        }
    }
    
    stats_file = os.path.join(output_dir, 'dataset_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2)
    print(f"âœ… å·²ä¿å­˜ç»Ÿè®¡ä¿¡æ¯: {stats_file}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 70)
    print("ğŸµ Amazon 2023 Musical Instruments æ•°æ®é›†è½¬æ¢å·¥å…· (ä¼˜åŒ–ç‰ˆ)")
    print("=" * 70)
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ç”¨æˆ·: YYYYXL1004")
    print("=" * 70)
    
    # é…ç½®
    BASE_DIR = './dataset/Instruments2023'
    REVIEW_FILE = os.path.join(BASE_DIR, 'Musical_Instruments.jsonl')
    META_FILE = os.path.join(BASE_DIR, 'meta_Musical_Instruments.jsonl')
    OUTPUT_DIR = BASE_DIR
    DATASET_NAME = 'Instruments2023'
    
    # ğŸ”§ ä¼˜åŒ–å‚æ•°
    MIN_USER_INTERACTIONS = 5  # ç”¨æˆ·æœ€å°‘äº¤äº’æ¬¡æ•°
    MIN_ITEM_INTERACTIONS = 5  # ç‰©å“æœ€å°‘äº¤äº’æ¬¡æ•°
    
    print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶:")
    print(f"   è¯„è®ºæ•°æ®: {REVIEW_FILE}")
    print(f"   å…ƒæ•°æ®: {META_FILE}")
    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"\nâš™ï¸  è¿‡æ»¤å‚æ•°:")
    print(f"   æœ€å°‘ç”¨æˆ·äº¤äº’: {MIN_USER_INTERACTIONS}")
    print(f"   æœ€å°‘ç‰©å“äº¤äº’: {MIN_ITEM_INTERACTIONS}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(REVIEW_FILE):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°è¯„è®ºæ–‡ä»¶ {REVIEW_FILE}")
        return
    
    # æ­¥éª¤ 1: åŠ è½½è¯„è®ºæ•°æ®
    reviews = load_reviews(REVIEW_FILE)
    
    # æ­¥éª¤ 2: é¢„å¤„ç†
    df = preprocess_reviews(reviews, MIN_USER_INTERACTIONS, MIN_ITEM_INTERACTIONS)
    
    # æ­¥éª¤ 3: ä¿å­˜ RecBole æ ¼å¼
    save_recbole_format(df, OUTPUT_DIR, DATASET_NAME)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ æ•°æ®è½¬æ¢å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. {OUTPUT_DIR}/{DATASET_NAME}.inter - RecBole äº¤äº’æ–‡ä»¶ âœ…")
    print(f"   2. {OUTPUT_DIR}/dataset_stats.json - æ•°æ®é›†ç»Ÿè®¡ âœ…")
    
    print(f"\nâœ¨ ä¸‹ä¸€æ­¥:")
    print(f"   è¿è¡Œ: python train_sasrec_instruments.py")
    print("=" * 70)

if __name__ == '__main__':
    main()